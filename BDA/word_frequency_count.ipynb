{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "import sys\n",
        "\n",
        "# Read input line by line\n",
        "for line in sys.stdin:\n",
        "    line = line.strip()\n",
        "    words = line.split()\n",
        "    for word in words:\n",
        "        print(f'{word}\\t1')\n"
      ],
      "metadata": {
        "id": "P7ZCdvrVE3Ie"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "import sys\n",
        "\n",
        "current_word = None\n",
        "current_count = 0\n",
        "\n",
        "# Input comes from standard input\n",
        "for line in sys.stdin:\n",
        "    word, count = line.strip().split('\\t')\n",
        "    try:\n",
        "        count = int(count)\n",
        "    except ValueError:\n",
        "        continue\n",
        "\n",
        "    if current_word == word:\n",
        "        current_count += count\n",
        "    else:\n",
        "        if current_word:\n",
        "            print(f'{current_word}\\t{current_count}')\n",
        "        current_word = word\n",
        "        current_count = count\n",
        "\n",
        "# Output the last word\n",
        "if current_word == word:\n",
        "    print(f'{current_word}\\t{current_count}')\n"
      ],
      "metadata": {
        "id": "b1yg-RDbGPxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Input File (input.txt):\n",
        "hello world welcome to the world of big data hello"
      ],
      "metadata": {
        "id": "LIsE3ByfGSQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Execution Commands:\n",
        "\n",
        "# Put input file into HDFS\n",
        "hadoop fs -put input.txt /input\n",
        "# Run MapReduce job\n",
        "hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \\\n",
        "-input /input/input.txt \\\n",
        "-output /output \\\n",
        "-mapper mapper.py \\\n",
        "-reducer reducer.py\n",
        "# View output\n",
        "hadoop fs -cat /output/part-00000"
      ],
      "metadata": {
        "id": "98IqoVbAGVu5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}